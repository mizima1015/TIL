# 1. 크롤링의 기본 개요

크롤링 : 데이터를 불러오는 것  
파싱 : 크롤링한 데이터에서 원하는 정보를 뽑아내는 것

요청 -> 웹 -> 응답 -> HTML

파싱 시 주의 사항 )  
xml, json, html, 여러 형태로 데이터를 받을 수 있음 어떤 데이터로 받는지 확인 중요


# 2. 웹에서 데이터를 수집하는 방법

* 웹사이트 직접 접근
	* 장점 : 원하는 만큼 데이터 수집 
	* 단점 : 데이터 직접 가공
	* 고려 사항 : 법적 문제 발생, UI변경 시, 모두 수정 -> 실무에서는 사용하기 힘들다.

* API 호출
	* 장점 : 정제된 데이터 획득
	* 단점 : API 호출 방식 학습 필수
	* 고려 사항 : 제한된 용량 및 유료화 



목적 : 분석에 필요한 데이터를 수집 , 취준생은 API 호출 방식 추천

# 3. 크롤링 할 때 주의사항

웹사이트 직접 접근 시 : robots.txt 확인 필수
-> 각 사이트마다 허용 범위가 다 다름
-> 계속 수집 시, IP 차단 가능성 존재
-> 교육용, 리서치용
-> 법적 분쟁 발생 가능성 다분

### 웹 크롤링은 인터넷 검색과 유사

| 절차 | 내용 | 주요 파이썬 라이브러리|
|------|-----------|----------|
| 요청 | GET 방식과 POST 방식의 HTTP 통신| request, selenium, scrapy|
| 응답 | 응답 결과 확인 (상태코드, 인코딩 방식)| |
|데이터 추출| 응답 받은 객체를 HTML으로 변환, CSS 또는 XPath로 HRML 요소 찾기, HTML 요소로부터 데이터추출 | scrapy, beautifulsoup|
|데이터 전처리 및 저장| 데이터 전처리 | pandas|



